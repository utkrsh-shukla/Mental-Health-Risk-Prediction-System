{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6477e65a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-18T22:24:58.388594Z",
     "iopub.status.busy": "2025-01-18T22:24:58.388251Z",
     "iopub.status.idle": "2025-01-18T22:24:59.299469Z",
     "shell.execute_reply": "2025-01-18T22:24:59.298200Z"
    },
    "papermill": {
     "duration": 0.916273,
     "end_time": "2025-01-18T22:24:59.301282",
     "exception": false,
     "start_time": "2025-01-18T22:24:58.385009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/depression-surveydataset-for-analysis/final_depression_dataset_1.csv\n",
      "/kaggle/input/analyze-the-insights-over-mental-health-data/sample_submission.csv\n",
      "/kaggle/input/analyze-the-insights-over-mental-health-data/train.csv\n",
      "/kaggle/input/analyze-the-insights-over-mental-health-data/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2416a340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-18T22:24:59.306862Z",
     "iopub.status.busy": "2025-01-18T22:24:59.306361Z",
     "iopub.status.idle": "2025-01-18T22:35:59.570568Z",
     "shell.execute_reply": "2025-01-18T22:35:59.569105Z"
    },
    "papermill": {
     "duration": 660.268707,
     "end_time": "2025-01-18T22:35:59.572325",
     "exception": false,
     "start_time": "2025-01-18T22:24:59.303618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (140700, 20)\n",
      "\n",
      "Column Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140700 entries, 0 to 140699\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                 Non-Null Count   Dtype  \n",
      "---  ------                                 --------------   -----  \n",
      " 0   id                                     140700 non-null  int64  \n",
      " 1   Name                                   140700 non-null  object \n",
      " 2   Gender                                 140700 non-null  object \n",
      " 3   Age                                    140700 non-null  float64\n",
      " 4   City                                   140700 non-null  object \n",
      " 5   Working Professional or Student        140700 non-null  object \n",
      " 6   Profession                             104070 non-null  object \n",
      " 7   Academic Pressure                      27897 non-null   float64\n",
      " 8   Work Pressure                          112782 non-null  float64\n",
      " 9   CGPA                                   27898 non-null   float64\n",
      " 10  Study Satisfaction                     27897 non-null   float64\n",
      " 11  Job Satisfaction                       112790 non-null  float64\n",
      " 12  Sleep Duration                         140700 non-null  object \n",
      " 13  Dietary Habits                         140696 non-null  object \n",
      " 14  Degree                                 140698 non-null  object \n",
      " 15  Have you ever had suicidal thoughts ?  140700 non-null  object \n",
      " 16  Work/Study Hours                       140700 non-null  float64\n",
      " 17  Financial Stress                       140696 non-null  float64\n",
      " 18  Family History of Mental Illness       140700 non-null  object \n",
      " 19  Depression                             140700 non-null  int64  \n",
      "dtypes: float64(8), int64(2), object(10)\n",
      "memory usage: 21.5+ MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "id                                            0\n",
      "Name                                          0\n",
      "Gender                                        0\n",
      "Age                                           0\n",
      "City                                          0\n",
      "Working Professional or Student               0\n",
      "Profession                                36630\n",
      "Academic Pressure                        112803\n",
      "Work Pressure                             27918\n",
      "CGPA                                     112802\n",
      "Study Satisfaction                       112803\n",
      "Job Satisfaction                          27910\n",
      "Sleep Duration                                0\n",
      "Dietary Habits                                4\n",
      "Degree                                        2\n",
      "Have you ever had suicidal thoughts ?         0\n",
      "Work/Study Hours                              0\n",
      "Financial Stress                              4\n",
      "Family History of Mental Illness              0\n",
      "Depression                                    0\n",
      "dtype: int64\n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[LightGBM] [Info] Number of positive: 20454, number of negative: 92106\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 482\n",
      "[LightGBM] [Info] Number of data points in the train set: 112560, number of used features: 125\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.181716 -> initscore=-1.504762\n",
      "[LightGBM] [Info] Start training from score -1.504762\n",
      "\n",
      "Training Accuracy: 0.9311389481165601\n",
      "Test Accuracy: 0.9177327647476902\n",
      "\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     23027\n",
      "           1       0.79      0.75      0.77      5113\n",
      "\n",
      "    accuracy                           0.92     28140\n",
      "   macro avg       0.87      0.85      0.86     28140\n",
      "weighted avg       0.92      0.92      0.92     28140\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[21990  1037]\n",
      " [ 1278  3835]]\n",
      "\n",
      "Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('/kaggle/input/analyze-the-insights-over-mental-health-data/train.csv')\n",
    "\n",
    "\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nColumn Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Handle Missing Values\n",
    "# Impute 'Profession' based on 'Working Professional or Student'\n",
    "data['Profession'] = data['Profession'].fillna(data['Working Professional or Student'])\n",
    "\n",
    "# Correctly identify numerical and categorical columns\n",
    "numerical_cols = ['Age', 'Work/Study Hours', 'CGPA', 'Financial Stress']  # Strictly numeric columns\n",
    "categorical_cols = ['Degree', 'Dietary Habits', 'Academic Pressure', 'Work Pressure', 'Study Satisfaction', 'Sleep Duration']\n",
    "\n",
    "# Impute numeric columns with the median\n",
    "data[numerical_cols] = data[numerical_cols].apply(pd.to_numeric, errors='coerce')  # Ensure numeric\n",
    "data[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].median())\n",
    "\n",
    "# Impute 'Sleep Duration' as categorical\n",
    "sleep_mapping = {\n",
    "    'Less than 5 hours': 1,\n",
    "    '5-6 hours': 2,\n",
    "    '6-7 hours': 3,\n",
    "    '7-8 hours': 4,\n",
    "    'More than 8 hours': 5\n",
    "}\n",
    "data['Sleep Duration'] = data['Sleep Duration'].map(sleep_mapping)\n",
    "\n",
    "# Fill remaining categorical columns with mode\n",
    "for col in categorical_cols:\n",
    "    if data[col].isnull().sum() > 0:  # Ensure the column has missing values\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "# Feature Engineering\n",
    "# Create a binary feature for missing values in 'Profession'\n",
    "data['is_profession_missing'] = data['Profession'].isnull().astype(int)\n",
    "\n",
    "# Bin ages into categories\n",
    "data['Age_Group'] = pd.cut(data['Age'], bins=[0, 18, 30, 45, 60], labels=['Teen', 'Young Adult', 'Middle-Aged', 'Senior'])\n",
    "\n",
    "# Drop redundant or less useful features (if needed)\n",
    "data = data.drop(columns=['id'])  # Assuming 'id' column exists\n",
    "\n",
    "# Prepare Data for Training\n",
    "X = data.drop(columns=['Depression'])\n",
    "y = data['Depression']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Encode Categorical Variables\n",
    "categorical_features = ['Gender', 'City', 'Working Professional or Student', 'Profession', 'Degree', \n",
    "                        'Dietary Habits', 'Academic Pressure', 'Work Pressure', 'Study Satisfaction', 'Age_Group']\n",
    "numerical_features = ['Age', 'Work/Study Hours', 'Sleep Duration', 'CGPA', 'Financial Stress']\n",
    "\n",
    "# Define preprocessors for categorical and numerical features\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define Model Pipeline\n",
    "model = LGBMClassifier(random_state=42)\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', model)])\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__max_depth': [10, 20, 30],\n",
    "    'classifier__num_leaves': [31, 50, 70]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Best Model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\nTraining Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"\\nClassification Report (Test):\\n\", classification_report(y_test, y_pred_test))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Generate Predictions for Submission\n",
    "# Assuming test.csv exists\n",
    "test_file_path = '/kaggle/input/analyze-the-insights-over-mental-health-data/test.csv'\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "test_data['Profession'] = test_data['Profession'].fillna(test_data['Working Professional or Student'])\n",
    "test_data[numerical_cols] = test_data[numerical_cols].apply(pd.to_numeric, errors='coerce')\n",
    "test_data[numerical_cols] = test_data[numerical_cols].fillna(test_data[numerical_cols].median())\n",
    "test_data['Sleep Duration'] = test_data['Sleep Duration'].map(sleep_mapping)\n",
    "for col in categorical_cols:\n",
    "    if col in test_data.columns:\n",
    "        test_data[col] = test_data[col].fillna(test_data[col].mode()[0])\n",
    "test_data['is_profession_missing'] = test_data['Profession'].isnull().astype(int)\n",
    "test_data['Age_Group'] = pd.cut(test_data['Age'], bins=[0, 18, 30, 45, 60], labels=['Teen', 'Young Adult', 'Middle-Aged', 'Senior'])\n",
    "\n",
    "# Drop redundant columns\n",
    "if 'id' in test_data.columns:\n",
    "    ids = test_data['id']\n",
    "    test_data = test_data.drop(columns=['id'])\n",
    "\n",
    "predictions = best_model.predict(test_data)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({'id': ids, 'Depression': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission file saved as 'submission.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10805499,
     "sourceId": 91482,
     "sourceType": "competition"
    },
    {
     "datasetId": 5868381,
     "sourceId": 9616093,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 664.86642,
   "end_time": "2025-01-18T22:36:00.496311",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-18T22:24:55.629891",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
